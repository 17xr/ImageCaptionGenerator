# Image Caption Generator

An image captioning model with support for different styles, inspired by Florence-2. It uses [facebook/dinov3](https://huggingface.co/facebook/dinov3-vits16plus-pretrain-lvd1689m) as the image encoder and leverages [intfloat/e5-base-v2](https://huggingface.co/intfloat/e5-base-v2) for the tokenizer and embeddings.

Its decoder follows a modern, Qwen 3-inspired architecture to generate high-quality captions. Developed in pure PyTorch for learning purposes, the model utilizes a self-attention only mechanism and supports KV caching for efficient inference. The project followed various Hugging Face training recipes and includes a FastAPI backend for inference and a Streamlit frontend for interactive use.

The model was trained on custom MS COCO captions generated by a local LLM, these are included in the data directory.

## ğŸ§® Requirements

- Python 3.8+
- A GPU is strongly recommended for inference at reasonable speed
- (Optional) Virtual environment to isolate dependencies

## ğŸ”§ Installation

1. Clone the repository:
```bash
git clone https://github.com/17xr/ImageCaptionGenerator.git
cd ImageWhisper
```

2. Install the Python dependencies:
```bash
pip install --no-cache-dir -r requirements.txt
```

3. (Optional) If you have CUDA/GPU support, ensure the correct PyTorch/CUDA version is installed.

## â–¶ï¸ Running the Application

### 1. Start the Backend

In the project root, run:
```bash
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000
```
This starts the HTTP API server (using Uvicorn) on port 8000.

### 2. Start the Frontend

In a separate terminal window, run:
```bash
cd frontend
streamlit run src/main.py
```
This launches the Streamlit UI in your browser.

### 3. Use the Application

- In the Streamlit UI, upload an image (or select a test image) and click "Generate Caption".
- The frontend sends the image to the backend, which runs the model and returns several captions.
- Captions are displayed in the UI by style.

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ dependencies.p
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ architecture/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ transformer.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ utils.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ concise/
â”‚   â”‚   â”œâ”€â”€ coco_train.csv
â”‚   â”‚   â”œâ”€â”€ coco_valid.csv
â”‚   â”‚   â””â”€â”€ coco_test.csv
â”‚   â”œâ”€â”€ narrative/
â”‚   â”‚   â”œâ”€â”€ coco_train.csv
â”‚   â”‚   â”œâ”€â”€ coco_valid.csv
â”‚   â”‚   â””â”€â”€ coco_test.csv
â”‚   â””â”€â”€ descriptive/
â”‚       â”œâ”€â”€ coco_train.csv
â”‚       â”œâ”€â”€ coco_valid.csv
â”‚       â””â”€â”€ coco_test.csv
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ main.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ weights.pt
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ training.ipynb
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ“„ License

This project is released under the MIT License. See the [LICENSE](LICENSE) file for details.
